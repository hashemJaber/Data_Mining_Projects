{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25e9d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycountry\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb15996-5783-4360-819c-8a488a4aa6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in /Users/hashemjaber/anaconda3/lib/python3.11/site-packages (2.6.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ed86d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Q1: GOING OUT?</th>\n",
       "      <th>Q2: GENDER</th>\n",
       "      <th>Q3: AGE</th>\n",
       "      <th>Q4: COUNTRY</th>\n",
       "      <th>Q5: STATE, PROVINCE, COUNTY, ETC</th>\n",
       "      <th>Q6 | 100 Grand Bar</th>\n",
       "      <th>Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)</th>\n",
       "      <th>Q6 | Any full-sized candy bar</th>\n",
       "      <th>Q6 | Black Jacks</th>\n",
       "      <th>...</th>\n",
       "      <th>Q8: DESPAIR OTHER</th>\n",
       "      <th>Q9: OTHER COMMENTS</th>\n",
       "      <th>Q10: DRESS</th>\n",
       "      <th>Unnamed: 113</th>\n",
       "      <th>Q11: DAY</th>\n",
       "      <th>Q12: MEDIA [Daily Dish]</th>\n",
       "      <th>Q12: MEDIA [Science]</th>\n",
       "      <th>Q12: MEDIA [ESPN]</th>\n",
       "      <th>Q12: MEDIA [Yahoo]</th>\n",
       "      <th>Click Coordinates (x, y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90258773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90272821</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>USA</td>\n",
       "      <td>NM</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bottom line is Twix is really the only candy w...</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(84, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90272829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>USA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90272840</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>us</td>\n",
       "      <td>or</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raisins can go to hell</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(75, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90272841</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>usa</td>\n",
       "      <td>exton pa</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White and gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(70, 10)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Internal ID Q1: GOING OUT? Q2: GENDER Q3: AGE Q4: COUNTRY  \\\n",
       "0     90258773            NaN        NaN     NaN         NaN   \n",
       "1     90272821             No       Male      44        USA    \n",
       "2     90272829            NaN       Male      49         USA   \n",
       "3     90272840             No       Male      40          us   \n",
       "4     90272841             No       Male      23         usa   \n",
       "\n",
       "  Q5: STATE, PROVINCE, COUNTY, ETC Q6 | 100 Grand Bar  \\\n",
       "0                              NaN                NaN   \n",
       "1                               NM                MEH   \n",
       "2                         Virginia                NaN   \n",
       "3                               or                MEH   \n",
       "4                         exton pa                JOY   \n",
       "\n",
       "  Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
       "0                                                NaN                                       \n",
       "1                                            DESPAIR                                       \n",
       "2                                                NaN                                       \n",
       "3                                            DESPAIR                                       \n",
       "4                                            DESPAIR                                       \n",
       "\n",
       "  Q6 | Any full-sized candy bar Q6 | Black Jacks  ... Q8: DESPAIR OTHER  \\\n",
       "0                           NaN              NaN  ...               NaN   \n",
       "1                           JOY              MEH  ...               NaN   \n",
       "2                           NaN              NaN  ...               NaN   \n",
       "3                           JOY              MEH  ...               NaN   \n",
       "4                           JOY          DESPAIR  ...               NaN   \n",
       "\n",
       "                                  Q9: OTHER COMMENTS      Q10: DRESS  \\\n",
       "0                                                NaN             NaN   \n",
       "1  Bottom line is Twix is really the only candy w...  White and gold   \n",
       "2                                                NaN             NaN   \n",
       "3                             Raisins can go to hell  White and gold   \n",
       "4                                                NaN  White and gold   \n",
       "\n",
       "  Unnamed: 113 Q11: DAY Q12: MEDIA [Daily Dish] Q12: MEDIA [Science]  \\\n",
       "0          NaN      NaN                     NaN                  NaN   \n",
       "1          NaN   Sunday                     NaN                  1.0   \n",
       "2          NaN      NaN                     NaN                  NaN   \n",
       "3          NaN   Sunday                     NaN                  1.0   \n",
       "4          NaN   Friday                     NaN                  1.0   \n",
       "\n",
       "  Q12: MEDIA [ESPN] Q12: MEDIA [Yahoo] Click Coordinates (x, y)  \n",
       "0               NaN                NaN                      NaN  \n",
       "1               NaN                NaN                 (84, 25)  \n",
       "2               NaN                NaN                      NaN  \n",
       "3               NaN                NaN                 (75, 23)  \n",
       "4               NaN                NaN                 (70, 10)  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv(\"/Users/davidcastrejon/Downloads/candyhierarchy2017.csv\", encoding=\"latin\")\n",
    "data = pd.read_csv(\"candyhierarchy2017.csv\", encoding=\"latin\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f970d",
   "metadata": {},
   "source": [
    "# Column 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a23645-5b6d-4a40-a507-898a6612304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes' 'no']\n"
     ]
    }
   ],
   "source": [
    "COLUMN_NAME = \"Q1: GOING OUT?\"\n",
    "# convert to lowercase\n",
    "data[COLUMN_NAME] = data[COLUMN_NAME].str.lower()\n",
    "# Get count of yes, no, nan.\n",
    "colOneValuesCount = data[COLUMN_NAME].astype(str).value_counts(dropna=False)\n",
    "yesCountPercentage = colOneValuesCount.get(\"yes\", 0) / (data[COLUMN_NAME].size - colOneValuesCount.get(\"nan\", 0))\n",
    "yesCountFill = round(yesCountPercentage * colOneValuesCount.get(\"nan\", 0))\n",
    "# shuffle the data frame\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "   # fill our nan values with yes according to the countFill\n",
    "try:\n",
    "    data[COLUMN_NAME].fillna(\"yes\", limit=yesCountFill, inplace=True)\n",
    "    data[COLUMN_NAME].fillna(\"no\", inplace=True)\n",
    "    data[COLUMN_NAME].unique()\n",
    "except:\n",
    "    pass\n",
    "colOneValuesCount\n",
    "\n",
    "# we can use regex validation for an extra layer of security (good for data integrity for large data sets)\n",
    "\n",
    "# define reg pattern to use\n",
    "regexPattern = r\"^(yes|no)$\"\n",
    "\n",
    "# parse through data to check if answers match regexPattern\n",
    "def process_going_out(going_out):\n",
    "    if re.match(regexPattern, going_out):\n",
    "        return going_out\n",
    "    else:\n",
    "        return 'no'\n",
    "\n",
    "data[COLUMN_NAME] = data[COLUMN_NAME].apply(process_going_out)\n",
    "print(data[COLUMN_NAME].unique())\n",
    "data[COLUMN_NAME] = data[COLUMN_NAME].map({'yes': 1, 'no': 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1add3",
   "metadata": {},
   "source": [
    "## Column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2419f59b-f3e2-4ed5-a8c8-1b11b0941212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Internal ID  Q1: GOING OUT? Q3: AGE    Q4: COUNTRY  \\\n",
      "0        90276841               1      49            usa   \n",
      "1        90286810               0      37  United States   \n",
      "2        90304431               0      19  united states   \n",
      "3        90277094               0      36         Canada   \n",
      "4        90287801               1      34            USA   \n",
      "...           ...             ...     ...            ...   \n",
      "2455     90284966               0      75          U.S.    \n",
      "2456     90275199               1      63            usa   \n",
      "2457     90280664               0      63             us   \n",
      "2458     90275444               0      55            Usa   \n",
      "2459     90287047               0      48  United States   \n",
      "\n",
      "     Q5: STATE, PROVINCE, COUNTY, ETC Q6 | 100 Grand Bar  \\\n",
      "0                                  mn                JOY   \n",
      "1                             Indiana                NaN   \n",
      "2                               texas                JOY   \n",
      "3                             Alberta                MEH   \n",
      "4                          California                NaN   \n",
      "...                               ...                ...   \n",
      "2455                               Va            DESPAIR   \n",
      "2456                     rhode island                JOY   \n",
      "2457                               pa                NaN   \n",
      "2458                      California                 MEH   \n",
      "2459                               OH                MEH   \n",
      "\n",
      "     Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)  \\\n",
      "0                                                   MEH                                       \n",
      "1                                                   NaN                                       \n",
      "2                                               DESPAIR                                       \n",
      "3                                                   MEH                                       \n",
      "4                                                   NaN                                       \n",
      "...                                                 ...                                       \n",
      "2455                                            DESPAIR                                       \n",
      "2456                                                MEH                                       \n",
      "2457                                                NaN                                       \n",
      "2458                                            DESPAIR                                       \n",
      "2459                                            DESPAIR                                       \n",
      "\n",
      "     Q6 | Any full-sized candy bar Q6 | Black Jacks Q6 | Bonkers (the candy)  \\\n",
      "0                              MEH              MEH                      MEH   \n",
      "1                              NaN              NaN                      NaN   \n",
      "2                              JOY          DESPAIR                  DESPAIR   \n",
      "3                              JOY              MEH                      MEH   \n",
      "4                              NaN              NaN                      NaN   \n",
      "...                            ...              ...                      ...   \n",
      "2455                           MEH          DESPAIR                  DESPAIR   \n",
      "2456                           JOY          DESPAIR                  DESPAIR   \n",
      "2457                           NaN              NaN                      NaN   \n",
      "2458                           JOY          DESPAIR                      MEH   \n",
      "2459                           JOY          DESPAIR                      MEH   \n",
      "\n",
      "      ... Q11: DAY Q12: MEDIA [Daily Dish] Q12: MEDIA [Science]  \\\n",
      "0     ...   Friday                     NaN                  1.0   \n",
      "1     ...      NaN                     NaN                  NaN   \n",
      "2     ...   Friday                     NaN                  NaN   \n",
      "3     ...   Friday                     NaN                  1.0   \n",
      "4     ...      NaN                     NaN                  NaN   \n",
      "...   ...      ...                     ...                  ...   \n",
      "2455  ...   Sunday                     NaN                  NaN   \n",
      "2456  ...   Sunday                     NaN                  1.0   \n",
      "2457  ...      NaN                     NaN                  NaN   \n",
      "2458  ...   Friday                     NaN                  1.0   \n",
      "2459  ...   Sunday                     1.0                  NaN   \n",
      "\n",
      "     Q12: MEDIA [ESPN] Q12: MEDIA [Yahoo] Click Coordinates (x, y)  \\\n",
      "0                  NaN                NaN                  (57, 5)   \n",
      "1                  NaN                NaN                      NaN   \n",
      "2                  NaN                1.0                 (81, 88)   \n",
      "3                  NaN                NaN                 (88, 32)   \n",
      "4                  NaN                NaN                      NaN   \n",
      "...                ...                ...                      ...   \n",
      "2455               NaN                NaN                      NaN   \n",
      "2456               NaN                NaN                  (59, 6)   \n",
      "2457               NaN                NaN                      NaN   \n",
      "2458               NaN                NaN                  (73, 5)   \n",
      "2459               NaN                NaN                 (33, 33)   \n",
      "\n",
      "     gender_female gender_i'd rather not say gender_male gender_other  \n",
      "0                0                         0           1            0  \n",
      "1                0                         0           1            0  \n",
      "2                0                         0           1            0  \n",
      "3                0                         0           1            0  \n",
      "4                0                         0           1            0  \n",
      "...            ...                       ...         ...          ...  \n",
      "2455             0                         0           1            0  \n",
      "2456             0                         0           1            0  \n",
      "2457             1                         0           0            0  \n",
      "2458             0                         0           1            0  \n",
      "2459             1                         0           0            0  \n",
      "\n",
      "[2460 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "COLUMN_NAME = \"Q2: GENDER\"  # Replace with the actual column name in your DataFrame\n",
    "\n",
    "# Convert to lowercase and fill NA values\n",
    "data[COLUMN_NAME] = data[COLUMN_NAME].str.lower()\n",
    "data[COLUMN_NAME].fillna(\"other\", inplace=True)\n",
    "\n",
    "# Define regex pattern\n",
    "regexPattern = r\"^(female|male|other|i'd rather not say)$\"\n",
    "\n",
    "# Function to process gender\n",
    "def process_gender(gender):\n",
    "    gender_str = str(gender)\n",
    "    match = re.match(regexPattern, gender_str)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# Apply the function to the gender column\n",
    "data[COLUMN_NAME] = data[COLUMN_NAME].apply(process_gender)\n",
    "\n",
    "# One-hot encode\n",
    "gender_dummies = pd.get_dummies(data[COLUMN_NAME], prefix='gender')\n",
    "data = pd.concat([data, gender_dummies], axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "data.drop([COLUMN_NAME], axis=1, inplace=True)\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffaf4e2",
   "metadata": {},
   "source": [
    "# Column 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f70836e-bfc1-43da-9c33-a0bd1645ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of non-numeric values in column Q3: AGE (should be empty): Empty DataFrame\n",
      "Columns: [Internal ID, Q1: GOING OUT?, Q3: AGE, Q4: COUNTRY, Q5: STATE, PROVINCE, COUNTY, ETC, Q6 | 100 Grand Bar, Q6 | Anonymous brown globs that come in black and orange wrappers\t(a.k.a. Mary Janes), Q6 | Any full-sized candy bar, Q6 | Black Jacks, Q6 | Bonkers (the candy), Q6 | Bonkers (the board game), Q6 | Bottle Caps, Q6 | Box'o'Raisins, Q6 | Broken glow stick, Q6 | Butterfinger, Q6 | Cadbury Creme Eggs, Q6 | Candy Corn, Q6 | Candy that is clearly just the stuff given out for free at restaurants, Q6 | Caramellos, Q6 | Cash, or other forms of legal tender, Q6 | Chardonnay, Q6 | Chick-o-Sticks (we donÃ•t know what that is), Q6 | Chiclets, Q6 | Coffee Crisp, Q6 | Creepy Religious comics/Chick Tracts, Q6 | Dental paraphenalia, Q6 | Dots, Q6 | Dove Bars, Q6 | Fuzzy Peaches, Q6 | Generic Brand Acetaminophen, Q6 | Glow sticks, Q6 | Goo Goo Clusters, Q6 | Good N' Plenty, Q6 | Gum from baseball cards, Q6 | Gummy Bears straight up, Q6 | Hard Candy, Q6 | Healthy Fruit, Q6 | Heath Bar, Q6 | Hershey's Dark Chocolate, Q6 | HersheyÃ•s Milk Chocolate, Q6 | Hershey's Kisses, Q6 | Hugs (actual physical hugs), Q6 | Jolly Rancher (bad flavor), Q6 | Jolly Ranchers (good flavor), Q6 | JoyJoy (Mit Iodine!), Q6 | Junior Mints, Q6 | Senior Mints, Q6 | Kale smoothie, Q6 | Kinder Happy Hippo, Q6 | Kit Kat, Q6 | LaffyTaffy, Q6 | LemonHeads, Q6 | Licorice (not black), Q6 | Licorice (yes black), Q6 | Lindt Truffle, Q6 | Lollipops, Q6 | Mars, Q6 | Maynards, Q6 | Mike and Ike, Q6 | Milk Duds, Q6 | Milky Way, Q6 | Regular M&Ms, Q6 | Peanut M&MÃ•s, Q6 | Blue M&M's, Q6 | Red M&M's, Q6 | Green Party M&M's, Q6 | Independent M&M's, Q6 | Abstained from M&M'ing., Q6 | Minibags of chips, Q6 | Mint Kisses, Q6 | Mint Juleps, Q6 | Mr. Goodbar, Q6 | Necco Wafers, Q6 | Nerds, Q6 | Nestle Crunch, Q6 | Now'n'Laters, Q6 | Peeps, Q6 | Pencils, Q6 | Pixy Stix, Q6 | Real Housewives of Orange County Season 9 Blue-Ray, Q6 | ReeseÃ•s Peanut Butter Cups, Q6 | Reese's Pieces, Q6 | Reggie Jackson Bar, Q6 | Rolos, Q6 | Sandwich-sized bags filled with BooBerry Crunch, Q6 | Skittles, Q6 | Smarties (American), Q6 | Smarties (Commonwealth), Q6 | Snickers, Q6 | Sourpatch Kids (i.e. abominations of nature), Q6 | Spotted Dick, Q6 | Starburst, Q6 | Sweet Tarts, Q6 | Swedish Fish, Q6 | Sweetums (a friend to diabetes), Q6 | Take 5, Q6 | Tic Tacs, Q6 | Those odd marshmallow circus peanut things, Q6 | Three Musketeers, Q6 | Tolberone something or other, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 123 columns]\n",
      "number of nulls in column Q3: AGE (should be 0): 0\n",
      "0       49.0\n",
      "1       37.0\n",
      "2       19.0\n",
      "3       36.0\n",
      "4       34.0\n",
      "        ... \n",
      "2455    75.0\n",
      "2456    63.0\n",
      "2457    63.0\n",
      "2458    55.0\n",
      "2459    48.0\n",
      "Name: Q3: AGE, Length: 2346, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "COLUMN_NAME = \"Q3: AGE\"\n",
    "# Unique\n",
    "#for the text data in the data frame that is age we can use reguaar expression to find the numbers and then convert them to numeric values\n",
    "#\n",
    "#\n",
    "\"\"\"\n",
    "[nan, '44', '49', '40', '23', '53', '33', '43', '56', '64', '37',\n",
    "       '59', '48', '54', '36', '45', '25', '34', '35', '38', '58', '50',\n",
    "       '47', '16', '52', '63', '65', '41', '27', '31', '61', '46', '42',\n",
    "       '62', '29', '39', '32', '28', '69', '67', '30', '22', '26', '51',\n",
    "       '70', '24', '18', '19', 'Old enough', '57', '60', '66', '12',\n",
    "       'Many', '55', '72', '?', '21', '11', 'no', '9', '68', '20', '6',\n",
    "       '10', '71', '90', '13', '45-55', '312', '99', '7', 'hahahahaha',\n",
    "       '88', '39.4', '74', '102', 'older than dirt', '17', '15', '8',\n",
    "       '75', '5u', 'Enough', 'See question 2', '24-50', '14', 'Over 50',\n",
    "       '100', '76', '1000', 'sixty-nine', '46 Halloweens.', 'ancient',\n",
    "       '77', 'OLD', 'old', '73', '70 1/2', '1', 'MY NAME JEFF', '4',\n",
    "       '59 on the day after Halloween', 'old enough', 'your mom',\n",
    "       'I can remember when Java was a cool new language', '60+']\n",
    "\"\"\"\n",
    "\n",
    "# Replace series as a numeric type rounded to the nearest whole number.\n",
    "data[COLUMN_NAME] = pd.to_numeric(data[COLUMN_NAME], errors='coerce').round() # convert to numeric values & round\n",
    "\n",
    "# remove columns which have values not in range 5-100\n",
    "data[COLUMN_NAME] = data[COLUMN_NAME][(data[COLUMN_NAME] >= 5) & (data[COLUMN_NAME] <= 100)]  # filter to only ages of 5-100\n",
    "# subsetcolumn label or sequence of labels, optional\n",
    "data.dropna(subset=[COLUMN_NAME], inplace=True) # drop all rows with nan values\n",
    "data[COLUMN_NAME]\n",
    "\n",
    "\n",
    "# double check if there are any non-numeric values, this should be empty:\n",
    "non_numeric_values = data[~data[COLUMN_NAME].apply(lambda x: np.isreal(x))]\n",
    "message = \"number of non-numeric values in column \" + COLUMN_NAME + \" (should be empty):\"\n",
    "print(message, non_numeric_values)\n",
    "\n",
    "# fill nil values with the median of the age column (or mean if you want, i commented that out)\n",
    "data[COLUMN_NAME].fillna(data[COLUMN_NAME].median(), inplace=True)\n",
    "# data[COLUMN_NAME].fillna(data[COLUMN_NAME].mean(), inplace=True)\n",
    "\n",
    "# double check to see if any nulls are left\n",
    "message = \"number of nulls in column \" + COLUMN_NAME + \" (should be 0):\"\n",
    "print (message, data[COLUMN_NAME].isna().sum())\n",
    "\n",
    "\n",
    "print(data[COLUMN_NAME]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9955a2f",
   "metadata": {},
   "source": [
    "# Column 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42a8cc05-c459-43b1-be53-bb3185160452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "united states     2011\n",
      "canada             222\n",
      "united kingdom      39\n",
      "other               18\n",
      "germany             10\n",
      "netherlands          7\n",
      "japan/korea          7\n",
      "china                4\n",
      "ireland              4\n",
      "mexico               4\n",
      "switzerland          3\n",
      "france               3\n",
      "sweden               2\n",
      "denmark              2\n",
      "south africa         1\n",
      "costa rica           1\n",
      "finland              1\n",
      "earth                1\n",
      "greece               1\n",
      "europe               1\n",
      "iceland              1\n",
      "indonesia            1\n",
      "singapore            1\n",
      "spain                1\n",
      "Name: Q4: COUNTRY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pycountry\n",
    "from autocorrect import Speller\n",
    "# use the pycountry and autocorrect libraries\n",
    "COLUMN_NAME = \"Q4: COUNTRY\"\n",
    "\n",
    "# initialize Speller obj from library\n",
    "spell = Speller()\n",
    "\n",
    "\n",
    "\n",
    "# function to autocorrect country names\n",
    "def autocorrectCountries(value):\n",
    "    value=value.lower()\n",
    "    orig=value\n",
    "    corrected_country = spell(value) # autocorrect name\n",
    "    try:\n",
    "        country = pycountry.countries.lookup(corrected_country) # look up country from pycountry\n",
    "        if country:\n",
    "            return country.name.lower() # if found, return the (lowercased) standard spelling\n",
    "    except Exception as e:\n",
    "        return orig              # else return nan (not sure if there's something better?)\n",
    "\n",
    "def standardize_country_name(name):\n",
    "    name = name.lower().strip()\n",
    "\n",
    "    # Remapping for United States\n",
    "    if any(keyword in name for keyword in ['us', 'u.s.', 'america', 'states', 'us of a', 'unhinged states', 'usa ', 'united state', 'unite states', \"'merica\", 'usausausa', 'u s ', 'u.s. ', 'u s a', \"usa? hard to tell anymore..\", \"i don't know anymore\", 'north carolina', 'new york', 'california', 'pittsburgh', 'new jersey', 'n. america', 'usa usa usa!!!!', 'usa! usa! usa!', 'murica', 'murrika']):\n",
    "        return 'united states'\n",
    "\n",
    "    # Remapping for United Kingdom\n",
    "    if any(keyword in name for keyword in ['uk', 'u.k.', 'england', 'united kingdom', 'scotland', 'uk ', 'u.k. ', 'endland']):\n",
    "        return 'united kingdom'\n",
    "\n",
    "    # Remapping for Canada\n",
    "    if any(keyword in name for keyword in ['canada', 'soviet canuckistan', 'i pretend to be from canada, but i am really from the united states.', 'canada ', 'canae', 'canada`']):\n",
    "        return 'canada'\n",
    "\n",
    "    # Remapping for United Arab Emirates\n",
    "    if 'united arab emirates' in name:\n",
    "        return 'united arab emirates'\n",
    "\n",
    "    # Remapping for China\n",
    "    if any(keyword in name for keyword in ['china', 'taiwan, province of china', 'hong kong']):\n",
    "        return 'china'\n",
    "\n",
    "    # ... additional remapping rules\n",
    "    if 'mexico' in name:\n",
    "        return 'mexico'\n",
    "\n",
    "    if 'iceland' in name:\n",
    "        return 'iceland'\n",
    "\n",
    "    if 'germany' in name:\n",
    "        return 'germany'\n",
    "\n",
    "    if any(keyword in name for keyword in ['netherlands', 'the netherlands']):\n",
    "        return 'netherlands'\n",
    "\n",
    "    if 'denmark' in name:\n",
    "        return 'denmark'\n",
    "\n",
    "    if any(keyword in name for keyword in ['ireland', 'ireland ']):\n",
    "        return 'ireland'\n",
    "\n",
    "    if 'indonesia' in name:\n",
    "        return 'indonesia'\n",
    "\n",
    "    if any(keyword in name for keyword in ['japan', 'korea', 'korea, republic of']):\n",
    "        return 'japan/korea'\n",
    "\n",
    "    if 'europe' in name:\n",
    "        return 'europe'\n",
    "\n",
    "    if 'switzerland' in name:\n",
    "        return 'switzerland'\n",
    "\n",
    "    if 'spain' in name:\n",
    "        return 'spain'\n",
    "\n",
    "    if any(keyword in name for keyword in ['france', 'france ']):\n",
    "        return 'france'\n",
    "\n",
    "    if 'sweden' in name:\n",
    "        return 'sweden'\n",
    "\n",
    "    if 'trumpistan' in name:\n",
    "        return 'fictional/cultural reference'\n",
    "\n",
    "    if 'finland' in name:\n",
    "        return 'finland'\n",
    "\n",
    "    if 'greece' in name:\n",
    "        return 'greece'\n",
    "\n",
    "    if 'south africa' in name:\n",
    "        return 'south africa'\n",
    "\n",
    "    if 'costa rica' in name:\n",
    "        return 'costa rica'\n",
    "\n",
    "    if 'singapore' in name:\n",
    "        return 'singapore'\n",
    "\n",
    "    if 'earth' in name:\n",
    "        return 'earth'\n",
    "\n",
    "    if 'narnia' in name or 'cascadia' in name or 'ud' in name:\n",
    "        return 'fictional/cultural reference'\n",
    "\n",
    "    if 'nan' in name:\n",
    "        return 'unknown'\n",
    "\n",
    "    # If name doesn't match any known patterns, keep it as is\n",
    "    return 'other'\n",
    "\n",
    "# Assuming data is your DataFrame\n",
    "COLUMN_NAME = \"Q4: COUNTRY\"\n",
    "data[COLUMN_NAME] = data[COLUMN_NAME].astype(str).apply(standardize_country_name)\n",
    "\n",
    "# Now print unique values to verify\n",
    "print(data[COLUMN_NAME].value_counts())\n",
    "\n",
    "    \n",
    "# apply to each country in column and retrieve all the unique names\n",
    "# data[COLUMN_NAME] = data[COLUMN_NAME].astype(str).apply(autocorrectCountries)\n",
    "# data[COLUMN_NAME].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf06a2ad",
   "metadata": {},
   "source": [
    "# Column 5\n",
    "\n",
    "- ### Oppenheimer this column ðŸ’£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Q5: STATE, PROVINCE, COUNTY, ETC'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8611b6",
   "metadata": {},
   "source": [
    "# Columns 5 - 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 5\n",
    "end_index = 106\n",
    "\n",
    "# Use list slicing to extract column names into a list\n",
    "sequential_column_names = data.columns[start_index:end_index + 1].tolist()\n",
    "\n",
    "for col in sequential_column_names:\n",
    "    # Use the 'replace' method to map values to '001', '010', '100'; Applying Hot Encoding\n",
    "    data[col] = data[col].replace({'JOY': '00001', 'MEH': '00010', 'MEH': '00100', 'DESPAIR': '01000', np.nan: '10000'})\n",
    "    data[col] = data[col].replace({'00001': 0, '00010': 1, '00100': 2, '01000': 3, '10000': 4})\n",
    "\n",
    "# Show the first few rows of the data frame\n",
    "# data.head()\n",
    "data.iloc[:, start_index:end_index].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Q3: AGE'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb147f",
   "metadata": {},
   "source": [
    "# Column 111?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ce08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAME = \"Q10: DRESS\"\n",
    "\n",
    "def hot_encoding_values(df, col):\n",
    "    nominal_values = df[col].unique().tolist()\n",
    "    \n",
    "    encoding_vals = {elem: idx for idx, elem in enumerate(nominal_values)}\n",
    "    \n",
    "    # can return the hashmap to see exactly what pertains to what as well. \n",
    "    \n",
    "    df[col].replace(encoding_vals, inplace=True)\n",
    "    print(df[col])\n",
    "    \n",
    "\n",
    "hot_encoding_values(data, COLUMN_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a56f8",
   "metadata": {},
   "source": [
    "# Column 112\n",
    "- ### Oppenheimer this column ðŸ’£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5489a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the empty cell column. \n",
    "data.drop(data.columns[112], axis=1, inplace=True)\n",
    "data.iloc[:, 112:113].head() # assuring the column was dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a8878",
   "metadata": {},
   "source": [
    "# Column 112 \n",
    "\n",
    "- ### This column is now 112, in the OG set it is 113. However we dropped an empty column with no useful information above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are nominal values as well so we can in theory apply hot encoding to these values pertaining to the date\n",
    "COLUMN_NAME = \"Q11: DAY\"\n",
    "COLUMN_NAME = data.columns[112]\n",
    "print(COLUMN_NAME)\n",
    "\n",
    "    \n",
    "    \n",
    "# encode the vals\n",
    "hot_encoding_values(data, COLUMN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4a83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ba0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
